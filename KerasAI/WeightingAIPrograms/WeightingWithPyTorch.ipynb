{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd9aeaee-3f21-4ea9-b5e8-069cedb5d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# This guide can only be run with the torch backend.\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "import torch\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c3698f-33ff-46cf-b689-4d01717f4383",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x, y = data\n",
    "\n",
    "        # Call torch.nn.Module.zero_grad() to clear the leftover gradients\n",
    "        # for the weights from the previous train step.\n",
    "        self.zero_grad()\n",
    "\n",
    "        # Compute loss\n",
    "        y_pred = self(x, training=True)  # Forward pass\n",
    "        loss = self.compute_loss(y=y, y_pred=y_pred)\n",
    "\n",
    "        # Call torch.Tensor.backward() on the loss to compute gradients\n",
    "        # for the weights.\n",
    "        loss.backward()\n",
    "\n",
    "        trainable_weights = [v for v in self.trainable_weights]\n",
    "        gradients = [v.value.grad for v in trainable_weights]\n",
    "\n",
    "        # Update weights\n",
    "        with torch.no_grad():\n",
    "            self.optimizer.apply(gradients, trainable_weights)\n",
    "\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        for metric in self.metrics:\n",
    "            if metric.name == \"loss\":\n",
    "                metric.update_state(loss)\n",
    "            else:\n",
    "                metric.update_state(y, y_pred)\n",
    "\n",
    "        # Return a dict mapping metric names to current value\n",
    "        # Note that it will include the loss (tracked in self.metrics).\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "182a1a6e-1e10-48e6-b340-bbe0be0a89e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - mae: 0.4673 - loss: 0.3336 \n",
      "Epoch 2/3\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - mae: 0.3693 - loss: 0.2052\n",
      "Epoch 3/3\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - mae: 0.3635 - loss: 0.1954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x71a4bc12ec20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct and compile an instance of CustomModel\n",
    "inputs = keras.Input(shape=(32,))\n",
    "outputs = keras.layers.Dense(1)(inputs)\n",
    "model = CustomModel(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "# Just use `fit` as usual\n",
    "x = np.random.random((1000, 32))\n",
    "y = np.random.random((1000, 1))\n",
    "model.fit(x, y, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a1376b5-a640-490d-a3fd-b513fc372ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1241 - mae: 0.9412\n",
      "Epoch 2/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4339 - mae: 0.5401\n",
      "Epoch 3/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2598 - mae: 0.4138\n",
      "Epoch 4/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2349 - mae: 0.3871\n",
      "Epoch 5/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2207 - mae: 0.3752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x71a4bc1d8250>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "        self.mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "        self.loss_fn = keras.losses.MeanSquaredError()\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        # Call torch.nn.Module.zero_grad() to clear the leftover gradients\n",
    "        # for the weights from the previous train step.\n",
    "        self.zero_grad()\n",
    "\n",
    "        # Compute loss\n",
    "        y_pred = self(x, training=True)  # Forward pass\n",
    "        loss = self.loss_fn(y, y_pred)\n",
    "\n",
    "        # Call torch.Tensor.backward() on the loss to compute gradients\n",
    "        # for the weights.\n",
    "        loss.backward()\n",
    "\n",
    "        trainable_weights = [v for v in self.trainable_weights]\n",
    "        gradients = [v.value.grad for v in trainable_weights]\n",
    "\n",
    "        # Update weights\n",
    "        with torch.no_grad():\n",
    "            self.optimizer.apply(gradients, trainable_weights)\n",
    "\n",
    "        # Compute our own metrics\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.mae_metric.update_state(y, y_pred)\n",
    "        return {\n",
    "            \"loss\": self.loss_tracker.result(),\n",
    "            \"mae\": self.mae_metric.result(),\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We list our `Metric` objects here so that `reset_states()` can be\n",
    "        # called automatically at the start of each epoch\n",
    "        # or at the start of `evaluate()`.\n",
    "        return [self.loss_tracker, self.mae_metric]\n",
    "\n",
    "\n",
    "# Construct an instance of CustomModel\n",
    "inputs = keras.Input(shape=(32,))\n",
    "outputs = keras.layers.Dense(1)(inputs)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "# We don't pass a loss or metrics here.\n",
    "model.compile(optimizer=\"adam\")\n",
    "\n",
    "# Just use `fit` as usual -- you can use callbacks, etc.\n",
    "x = np.random.random((1000, 32))\n",
    "y = np.random.random((1000, 1))\n",
    "model.fit(x, y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fdc721d-05d3-4cfa-8bf3-39d2f2b76b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - mae: 0.4838 - loss: 0.1794\n",
      "Epoch 2/3\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - mae: 0.4274 - loss: 0.1409\n",
      "Epoch 3/3\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - mae: 0.4249 - loss: 0.1276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x71a4bc007940>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        if len(data) == 3:\n",
    "            x, y, sample_weight = data\n",
    "        else:\n",
    "            sample_weight = None\n",
    "            x, y = data\n",
    "\n",
    "        # Call torch.nn.Module.zero_grad() to clear the leftover gradients\n",
    "        # for the weights from the previous train step.\n",
    "        self.zero_grad()\n",
    "\n",
    "        # Compute loss\n",
    "        y_pred = self(x, training=True)  # Forward pass\n",
    "        loss = self.compute_loss(\n",
    "            y=y,\n",
    "            y_pred=y_pred,\n",
    "            sample_weight=sample_weight,\n",
    "        )\n",
    "\n",
    "        # Call torch.Tensor.backward() on the loss to compute gradients\n",
    "        # for the weights.\n",
    "        loss.backward()\n",
    "\n",
    "        trainable_weights = [v for v in self.trainable_weights]\n",
    "        gradients = [v.value.grad for v in trainable_weights]\n",
    "\n",
    "        # Update weights\n",
    "        with torch.no_grad():\n",
    "            self.optimizer.apply(gradients, trainable_weights)\n",
    "\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        for metric in self.metrics:\n",
    "            if metric.name == \"loss\":\n",
    "                metric.update_state(loss)\n",
    "            else:\n",
    "                metric.update_state(y, y_pred, sample_weight=sample_weight)\n",
    "\n",
    "        # Return a dict mapping metric names to current value\n",
    "        # Note that it will include the loss (tracked in self.metrics).\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "\n",
    "# Construct and compile an instance of CustomModel\n",
    "inputs = keras.Input(shape=(32,))\n",
    "outputs = keras.layers.Dense(1)(inputs)\n",
    "model = CustomModel(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "# You can now use sample_weight argument\n",
    "x = np.random.random((1000, 32))\n",
    "y = np.random.random((1000, 1))\n",
    "sw = np.random.random((1000, 1))\n",
    "model.fit(x, y, sample_weight=sw, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "536ee83f-33cb-45eb-88bb-45a214cca79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - mae: 0.6388 - loss: 0.5674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.55035001039505, 0.6292902231216431]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y = data\n",
    "        # Compute predictions\n",
    "        y_pred = self(x, training=False)\n",
    "        # Updates the metrics tracking the loss\n",
    "        loss = self.compute_loss(y=y, y_pred=y_pred)\n",
    "        # Update the metrics.\n",
    "        for metric in self.metrics:\n",
    "            if metric.name == \"loss\":\n",
    "                metric.update_state(loss)\n",
    "            else:\n",
    "                metric.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value.\n",
    "        # Note that it will include the loss (tracked in self.metrics).\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "\n",
    "# Construct an instance of CustomModel\n",
    "inputs = keras.Input(shape=(32,))\n",
    "outputs = keras.layers.Dense(1)(inputs)\n",
    "model = CustomModel(inputs, outputs)\n",
    "model.compile(loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "# Evaluate with our custom test_step\n",
    "x = np.random.random((1000, 32))\n",
    "y = np.random.random((1000, 1))\n",
    "model.evaluate(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5803772d-2921-4cdb-9857-8046303b2cba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
